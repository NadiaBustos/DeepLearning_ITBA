{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79317b06",
   "metadata": {},
   "source": [
    "# OCR con DOCTR\n",
    "\n",
    "DocTR (Document Text Recognition) es una librería open-source de OCR basada en deep learning creada por Mindee.\n",
    "Proporciona un pipeline end-to-end con dos componentes principales:\n",
    "\n",
    "- Detector de texto: Delimita automáticamente las regiones que contienen palabras o líneas, sin necesidad de utilizar otras herramientas (como hicimos con PyMuPDF para correr Tesseract). El dectector analiza la imagen, localiza dónde hay palabras/líneas y dibuja “cajas” (bounding boxes).\n",
    "\n",
    "- Reconocedor de texto: Transforma cada región en caracteres, para ello recorta cada caja y convierte los píxeles en caracteres (CNN + RNN/Transformer).\n",
    "\n",
    "Seleccionamos este modelo porque tiene alto recall en documentos reales, maneja  márgenes, sellos, firmas y layouts irregulares que aparecen en cartas documento escaneadas. Documentación disponible en https://mindee.github.io/doctr/index.html\n",
    "\n",
    "Su instalación es bastante sencilla, solo hay que importar las librerías en la terminal. Para mayor información, ver archivo \"Readme_DOCTR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c508fd1",
   "metadata": {},
   "source": [
    "1) Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfd745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\entornos\\trocr_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53baab5",
   "metadata": {},
   "source": [
    "2. Definimos las rutas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR  = r\"D:\\Formación\\Managment & Analytics - ITBA\\15. Deep Learning\\CDs_Ejemplo\\CDs_Ejemplo\"\n",
    "OUT_DIR = r\"D:\\Formación\\Managment & Analytics - ITBA\\15. Deep Learning\\CDs_Ejemplo\\Extraccion_DOCTR\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df651c63",
   "metadata": {},
   "source": [
    "3. Definimos los parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d620a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\entornos\\trocr_env\\lib\\site-packages\\torch\\cuda\\__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "DET_ARCH          = \"db_mobilenet_v3_large\"   # detector rápido y preciso :contentReference[oaicite:0]{index=0}\n",
    "RECO_ARCH         = \"sar_resnet31\"            # reconocedor robusto a tildes :contentReference[oaicite:1]{index=1}\n",
    "DET_BS, RECO_BS   = 4, 512                    # batch sizes seguros para 6 GB VRAM :contentReference[oaicite:2]{index=2}\n",
    "ASSUME_STRAIGHT   = False                     # deja que detecte rotación :contentReference[oaicite:3]{index=3}\n",
    "DEVICE            = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "FP16              = DEVICE == \"cuda\"          # medio flotante sólo en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb44b8a",
   "metadata": {},
   "source": [
    "4. Instanciamos el modelo y configuramos los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62081ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\entornos\\trocr_env\\lib\\site-packages\\doctr\\models\\utils\\pytorch.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(archive_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = ocr_predictor(\n",
    "    det_arch=DET_ARCH,\n",
    "    reco_arch=RECO_ARCH,\n",
    "    pretrained=True,\n",
    "    det_bs=DET_BS,\n",
    "    reco_bs=RECO_BS,\n",
    "    assume_straight_pages=ASSUME_STRAIGHT,\n",
    "    detect_orientation=True,          # clasificador de orientación de página\n",
    "    straighten_pages=True,            # deskew suave\n",
    "    preserve_aspect_ratio=True,       # evita distorsión\n",
    "    symmetric_pad=True,               # paddings parejos\n",
    "    resolve_blocks=False,             # sólo texto plano\n",
    ").to(DEVICE)\n",
    "\n",
    "if FP16:\n",
    "    model = model.half()             #  reduce VRAM :contentReference[oaicite:4]{index=4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1a789",
   "metadata": {},
   "source": [
    "5. Definimos una función para convertir en texto plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0d2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plano(p):\n",
    "    return \"\\n\".join(\n",
    "        \" \".join(w[\"value\"] for w in l.get(\"words\", []))\n",
    "        for b in p.get(\"blocks\", [])\n",
    "        for l in b.get(\"lines\", [])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d3cbf",
   "metadata": {},
   "source": [
    "6. Recorremos todos los archivos del repositorio y aplicamos el OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea5f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belen_payway.pdf: 1 pág(s)\n",
      "✔ Guardado Belen_payway.txt\n",
      "Bruno23689270.pdf: 1 pág(s)\n",
      "✔ Guardado Bruno23689270.txt\n",
      "Bruno400212294002.pdf: 1 pág(s)\n",
      "✔ Guardado Bruno400212294002.txt\n",
      "Bruno400212294002_1.pdf: 1 pág(s)\n",
      "✔ Guardado Bruno400212294002_1.txt\n",
      "Coyle401547680601.pdf: 1 pág(s)\n",
      "✔ Guardado Coyle401547680601.txt\n",
      "EVERTEC30707869484.pdf: 1 pág(s)\n",
      "✔ Guardado EVERTEC30707869484.txt\n",
      "Galicia_Giuseppe.pdf: 1 pág(s)\n",
      "✔ Guardado Galicia_Giuseppe.txt\n",
      "hsbc_Aquino.pdf: 1 pág(s)\n",
      "✔ Guardado hsbc_Aquino.txt\n",
      "hsbc_Aquino2.pdf: 1 pág(s)\n",
      "✔ Guardado hsbc_Aquino2.txt\n",
      "hsbc_Aquino3.pdf: 1 pág(s)\n",
      "✔ Guardado hsbc_Aquino3.txt\n",
      "Mallo12980371.pdf: 1 pág(s)\n",
      "✔ Guardado Mallo12980371.txt\n",
      "Pantano28462989.pdf: 1 pág(s)\n",
      "✔ Guardado Pantano28462989.txt\n",
      "Santander_evertec.pdf: 1 pág(s)\n",
      "✔ Guardado Santander_evertec.txt\n"
     ]
    }
   ],
   "source": [
    "for fname in os.listdir(IN_DIR):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    pdf_path = os.path.join(IN_DIR, fname)\n",
    "    try:\n",
    "        # Rasteriza a ~300 dpi, escala = 2 (72 dpi × 2 ≈ 144 dpi por pulgada lógica de pdfium) :contentReference[oaicite:5]{index=5}\n",
    "        doc = DocumentFile.from_pdf(pdf_path, scale=2)\n",
    "        print(f\"{fname}: {len(doc)} pág(s)\")\n",
    "\n",
    "        result = model(doc).export()[\"pages\"]\n",
    "        texto = []\n",
    "        for i, page in enumerate(result, start=1):\n",
    "            texto.append(f\"\\n--- Página {i} ---\\n\")\n",
    "            texto.append(plano(page))\n",
    "\n",
    "        txt_name = os.path.splitext(fname)[0] + \".txt\"\n",
    "        with open(os.path.join(OUT_DIR, txt_name), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\".join(texto))\n",
    "\n",
    "        print(f\"✔ Guardado {txt_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✖ Error en {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd95ec",
   "metadata": {},
   "source": [
    "## Estracción de variables con LLama 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40849e8b",
   "metadata": {},
   "source": [
    "Vamos a seguir la misma lógica de extracción de variables que utilizamos con Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa8f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\entornos\\trocr_env\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: tqdm in d:\\entornos\\trocr_env\\lib\\site-packages (4.67.1)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\entornos\\trocr_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\entornos\\trocr_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\entornos\\trocr_env\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\entornos\\trocr_env\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: colorama in d:\\entornos\\trocr_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\entornos\\trocr_env\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 9.9 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic\n",
      "\n",
      "   ---------------------------------------- 0/4 [typing-inspection]\n",
      "   ---------- ----------------------------- 1/4 [pydantic-core]\n",
      "   ---------- ----------------------------- 1/4 [pydantic-core]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ------------------------------ --------- 3/4 [pydantic]\n",
      "   ---------------------------------------- 4/4 [pydantic]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests tqdm pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d129955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from pydantic import ValidationError\n",
    "import re, unicodedata\n",
    "from tqdm import tqdm\n",
    "from requests.exceptions import ReadTimeout\n",
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from requests.exceptions import ReadTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6618cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_FOLDER = r\"D:\\Formación\\Managment & Analytics - ITBA\\15. Deep Learning\\CDs_Ejemplo\\Extraccion_DOCTR\"\n",
    "OUTPUT_CSV = \"entidades_extraidas_DOCTR.csv\"\n",
    "PROMPT_FILE = \"prompt_2.txt\"\n",
    "MODEL       = \"llama3:latest\"\n",
    "OLLAMA_URL  = \"http://localhost:11434/api/generate\"\n",
    "TEMPERATURE = 0.0\n",
    "TIMEOUT     = 800\n",
    "MAX_CHARS   = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa63117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity(BaseModel):\n",
    "    Remitente: Optional[str] = None\n",
    "    DNI: Optional[str] = None\n",
    "    CUIT_CUIL: Optional[str] = None\n",
    "    Cuerpo: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74e1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_RE = re.compile(r\"[^\\w\\s.,;:()@€$%/-]\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = CLEAN_RE.sub(\"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f1fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Remitente\": {\"type\": [\"string\", \"null\"]},\n",
    "        \"DNI\": {\"type\": [\"string\", \"null\"], \"pattern\": \"^\\\\d*$\"},\n",
    "        \"CUIT_CUIL\": {\"type\": [\"string\", \"null\"], \"pattern\": \"^\\\\d*$\"},\n",
    "        \"Cuerpo\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"Cuerpo\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "with open(PROMPT_FILE, encoding=\"utf-8\") as f:\n",
    "    PROMPT = f.read()\n",
    "\n",
    "def call_ollama(text: str) -> dict:\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": f\"<|system|>\\n{PROMPT}<|end|>\\n<|user|>\\n{text[:MAX_CHARS]}<|end|>\\n<|assistant|>\",\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": TEMPERATURE, \"json_schema\": JSON_SCHEMA},\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)\n",
    "    except ReadTimeout:\n",
    "        raise TimeoutError(\"Timeout de Ollama\")\n",
    "    r.raise_for_status()\n",
    "    return json.loads(r.json()[\"response\"])\n",
    "\n",
    "def main():\n",
    "    dir_path = Path(TXT_FOLDER)\n",
    "    if not dir_path.is_dir():\n",
    "        raise SystemExit(f\"Ruta no encontrada: {dir_path}\")\n",
    "\n",
    "    rows = []\n",
    "    for file in tqdm(sorted(dir_path.glob(\"*.txt\")), desc=\"TXT\"):\n",
    "        raw = file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        cleaned = clean_text(raw)\n",
    "        try:\n",
    "            data = call_ollama(cleaned)\n",
    "            ent = Entity.model_validate(data)\n",
    "            rows.append({\n",
    "                \"ARCHIVO\": file.name,\n",
    "                \"Remitente\": (ent.Remitente or \"NaN\").strip() or \"NaN\",\n",
    "                \"DNI\": re.sub(r\"\\D\", \"\", ent.DNI or \"\") or \"NaN\",\n",
    "                \"CUIT_CUIL\": re.sub(r\"\\D\", \"\", ent.CUIT_CUIL or \"\") or \"NaN\",\n",
    "                \"Cuerpo\": ent.Cuerpo.strip() or \"NaN\",\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file.name}: {e}\")\n",
    "    if rows:\n",
    "        with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.DictWriter(f, fieldnames=rows[0].keys()).writeheader(); csv.DictWriter(f, fieldnames=rows[0].keys()).writerows(rows)\n",
    "        print(f\"✅ CSV generado en {OUTPUT_CSV} ({len(rows)} filas)\")\n",
    "    else:\n",
    "        print(\"No se extrajeron entidades válidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af829b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TXT:  46%|████▌     | 6/13 [1:34:04<1:50:18, 945.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ EVERTEC30707869484.txt: Timeout de Ollama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TXT: 100%|██████████| 13/13 [1:59:02<00:00, 549.43s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV generado en entidades_extraidas_DOCTR.csv (12 filas)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
