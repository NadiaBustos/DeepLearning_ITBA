{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caad85b2",
   "metadata": {},
   "source": [
    "# OCR con Tesseract\n",
    "\n",
    "Tesseract convierte imágenes en texto en cuatro pasos básicos:\n",
    "\n",
    "- Preprocesado y binarización: Convierte la imagen a blanco y negro con umbrales adaptativos para destacar los trazos de tinta y reducir ruido.\n",
    "\n",
    "- Segmentación: Encuentra los contornos (“blobs”) de los caracteres, agrupa blobs en líneas y luego en palabras usando análisis de componentes conectados y proyección vertical/horizontal.\n",
    "\n",
    "- Reconocimiento: Hasta la versión 3 usaba un clasificador basado en patrones y árboles de decisiones. Desde la versión 4 (la que usamos en este análisis) emplea redes LSTM bidireccionales que procesan la secuencia de píxeles línea por línea y generan la probabilidad de cada carácter.\n",
    "\n",
    "- Post-procesado: Aplica un modelo de lenguaje y diccionarios para corregir errores típicos (p. ej. confundir “0” y “O”), calcular la confianza y producir el texto final.\n",
    "\n",
    "La documentación de la librería está disponible en https://tesseract-ocr.github.io/tessdoc/tess4/NeuralNetsInTesseract4.00.html?utm_source=chatgpt.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ebb0c",
   "metadata": {},
   "source": [
    "## Lectura y extracción de texto\n",
    "Este script extrae texto de PDFs escaneados usando **PyMuPDF** y utilizando Optical Caracter Recognition de **Tesseract**.  \n",
    "Antes de correrlo, recomendamos leer los requisitos en readme_ocr-pdf-extractor de este repositorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae2883",
   "metadata": {},
   "source": [
    "1) Vamos a instalar las librerías necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisitos previos (solo una vez):\n",
    "#%pip install pymupdf pillow pytesseract\n",
    "#   Instalar Tesseract y el idioma español (spa.traineddata) en la computadora (ver instrucciones en el readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456a7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, re, unicodedata\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from requests.exceptions import ReadTimeout\n",
    "from pydantic import ValidationError\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb935e9",
   "metadata": {},
   "source": [
    "2) Definimos una ruta a los archivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5439738",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FOLDER    = Path(\"cds_ejemplo\")\n",
    "OUTPUT_FOLDER = Path(\"outputs\") / \"Extraccion_Tesseract\"\n",
    "\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bda4c",
   "metadata": {},
   "source": [
    "3) Vamos a definir un diccionario con los parámetros del OCR:\n",
    "\n",
    "- DPI: resolución para renderizar la página (default 300).\n",
    "- Lang: idioma OCR (español).\n",
    "- Mode: Dejamos la configuración default que posee un perfil OCR con LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d674a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = \"spa\"     \n",
    "DPI = 300      \n",
    "PSM = 6          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7b504",
   "metadata": {},
   "source": [
    "4) Definimos una la función *pdf_to_images* que recorre el pdf y convierte cada página en imagen, extrae el texto  con PyMuPDF y lo guarda. Este paso es importante para después poder aplicar el OCR.  \n",
    "Luego, definimos la función *ocr_pdf* para procesar los PDFs y guardar el TXT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb5b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path: Path, dpi: int):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    zoom = dpi / 72\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "    for page in doc:\n",
    "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        yield Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "\n",
    "def ocr_pdf(pdf_path: Path) -> str:\n",
    "    texto = []\n",
    "    for img in pdf_to_images(pdf_path, DPI):\n",
    "        texto.append(\n",
    "            pytesseract.image_to_string(img, lang=LANG, config=f\"--psm {PSM}\")\n",
    "        )\n",
    "    return \"\\n\".join(texto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36caf2ae",
   "metadata": {},
   "source": [
    "5) Ejecutamos el OCR en todos los PDFs de la carpeta y guardamos el texto extraído en archivos .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94891f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Belen_payway.pdf…\n",
      "Procesando Bruno23689270.pdf…\n",
      "Procesando Bruno400212294002.pdf…\n",
      "Procesando Bruno400212294002_1.pdf…\n",
      "Procesando Coyle401547680601.pdf…\n",
      "Procesando EVERTEC30707869484.pdf…\n",
      "Procesando Galicia_Giuseppe.pdf…\n",
      "Procesando hsbc_Aquino.pdf…\n",
      "Procesando hsbc_Aquino2.pdf…\n",
      "Procesando hsbc_Aquino3.pdf…\n",
      "Procesando Mallo12980371.pdf…\n",
      "Procesando Pantano28462989.pdf…\n",
      "Procesando Santander_evertec.pdf…\n",
      "Listo. Archivos guardados en D:\\Formación\\Managment & Analytics - ITBA\\15. Deep Learning\\Trabajo_Final\\outputs\\Extraccion_Tesseract\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    in_dir = Path(PDF_FOLDER)\n",
    "    out_dir = Path(OUTPUT_FOLDER)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pdfs = list(in_dir.glob(\"*.pdf\"))\n",
    "    if not pdfs:\n",
    "        print(f\"No se encontraron PDFs en {in_dir.resolve()}\")\n",
    "        return\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        print(f\"Procesando {pdf.name}…\")\n",
    "        texto = ocr_pdf(pdf)\n",
    "        (out_dir / f\"{pdf.stem}.txt\").write_text(texto, encoding=\"utf-8\")\n",
    "    print(\"Listo. Archivos guardados en\", out_dir.resolve())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a6341",
   "metadata": {},
   "source": [
    "## Extracción de variables con Llama 3\n",
    "Vamos a utilizar structured outputs para extraer información de los txt y transformarlos en variables. Esto nos facilitará la evaluación de la calidad del OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43facfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_FOLDER = Path(\"outputs\") / \"Extraccion_Tesseract\"\n",
    "OUTPUT_CSV = Path(\"entidades_extraidas_Tesseract.csv\")\n",
    "PROMPT_FILE = \"prompt_2.txt\"\n",
    "MODEL       = \"llama3:latest\"\n",
    "OLLAMA_URL  = \"http://localhost:11434/api/generate\"\n",
    "TEMPERATURE = 0.0\n",
    "TIMEOUT     = 900\n",
    "MAX_CHARS   = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42ec3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity(BaseModel):\n",
    "    Remitente: Optional[str] = None\n",
    "    DNI: Optional[str] = None\n",
    "    CUIT_CUIL: Optional[str] = None\n",
    "    Cuerpo: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be4f90",
   "metadata": {},
   "source": [
    "Vamos a generar una función para eliminar caracteres especiales y saltos de línea del texto extraído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10f0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_RE = re.compile(r\"[^\\w\\s.,;:()@€$%/-]\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = CLEAN_RE.sub(\"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16aca9a",
   "metadata": {},
   "source": [
    "Definimos una función para extraer entidades con llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e0125dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Remitente\": {\"type\": [\"string\", \"null\"]},\n",
    "        \"DNI\": {\"type\": [\"string\", \"null\"], \"pattern\": \"^\\\\d*$\"},\n",
    "        \"CUIT_CUIL\": {\"type\": [\"string\", \"null\"], \"pattern\": \"^\\\\d*$\"},\n",
    "        \"Cuerpo\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"Cuerpo\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "with open(PROMPT_FILE, encoding=\"utf-8\") as f:\n",
    "    PROMPT = f.read()\n",
    "\n",
    "def call_ollama(text: str) -> dict:\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": f\"<|system|>\\n{PROMPT}<|end|>\\n<|user|>\\n{text[:MAX_CHARS]}<|end|>\\n<|assistant|>\",\n",
    "        \"format\": \"json\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": TEMPERATURE, \"json_schema\": JSON_SCHEMA},\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)\n",
    "    except ReadTimeout:\n",
    "        raise TimeoutError(\"Timeout de Ollama\")\n",
    "    r.raise_for_status()\n",
    "    return json.loads(r.json()[\"response\"])\n",
    "\n",
    "def main():\n",
    "    dir_path = Path(TXT_FOLDER)\n",
    "    if not dir_path.is_dir():\n",
    "        raise SystemExit(f\"Ruta no encontrada: {dir_path}\")\n",
    "\n",
    "    rows = []\n",
    "    for file in tqdm(sorted(dir_path.glob(\"*.txt\")), desc=\"TXT\"):\n",
    "        raw = file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        cleaned = clean_text(raw)\n",
    "        try:\n",
    "            data = call_ollama(cleaned)\n",
    "            ent = Entity.model_validate(data)\n",
    "            rows.append({\n",
    "                \"ARCHIVO\": file.name,\n",
    "                \"Remitente\": (ent.Remitente or \"NaN\").strip() or \"NaN\",\n",
    "                \"DNI\": re.sub(r\"\\D\", \"\", ent.DNI or \"\") or \"NaN\",\n",
    "                \"CUIT_CUIL\": re.sub(r\"\\D\", \"\", ent.CUIT_CUIL or \"\") or \"NaN\",\n",
    "                \"Cuerpo\": ent.Cuerpo.strip() or \"NaN\",\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file.name}: {e}\")\n",
    "    if rows:\n",
    "        with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.DictWriter(f, fieldnames=rows[0].keys()).writeheader(); csv.DictWriter(f, fieldnames=rows[0].keys()).writerows(rows)\n",
    "        print(f\"✅ CSV generado en {OUTPUT_CSV} ({len(rows)} filas)\")\n",
    "    else:\n",
    "        print(\"No se extrajeron entidades válidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a8d76",
   "metadata": {},
   "source": [
    "Ejecutamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35755c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TXT: 100%|██████████| 13/13 [1:29:20<00:00, 412.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV generado en entidades_extraidas_Tesseract.csv (13 filas)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde7e4e",
   "metadata": {},
   "source": [
    "La extracción de entidades logró detectar bien el nombre del remitente y el cuerpo, pero presenta dificultades para leer DNI y CUIT. Esto podría resolverse utilizando un modelo más grande, que reconozca con más facilidad ese tipo de variables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
